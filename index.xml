<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yesphet</title>
    <link>https://yesphet.github.io/</link>
    <description>Recent content on Yesphet</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Mar 2020 18:05:51 +0800</lastBuildDate>
    
	<atom:link href="https://yesphet.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Linux内核版本及发行版版本介绍</title>
      <link>https://yesphet.github.io/posts/linux%E5%86%85%E6%A0%B8%E7%89%88%E6%9C%AC%E5%8F%8A%E5%8F%91%E8%A1%8C%E7%89%88%E7%89%88%E6%9C%AC%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Thu, 19 Mar 2020 18:05:51 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/linux%E5%86%85%E6%A0%B8%E7%89%88%E6%9C%AC%E5%8F%8A%E5%8F%91%E8%A1%8C%E7%89%88%E7%89%88%E6%9C%AC%E4%BB%8B%E7%BB%8D/</guid>
      <description>前段时间在排查一个TCP丢包没有重传的问题，最后定位到是由于线上机器内核存在问题导致的。排查期间发现对于Linux内核版本、CentOS版本等各种版本有点傻傻分不清楚，因此今天整理一下。
Linux 内核介绍 Linux 内核介绍直接参考 WIKI
Linux 内核版本命名规范经历过三次调整。3.0 以前的版本号规范历史可以参考 Linux Kernel Version Numbering 这篇。从3.0之后，版本号的格式都是 x.y.z，并没有遵循 Semantic Versioning ，查阅了一些资料感觉并没有什么固定的版本号规范，不过这也不重要就是了，只需要从Linux官网 https://kernel.org/ 查询最新的版本即可，在官网中：
 mainline 表示主线版本 stable 表示稳定版，由mainline在实际成熟时发布 longterm （Long Term Support, LTS）长期支持版，当不再支持时会标记EOL（End Of Life）  需要注意的是从 2.6 之后，好像就不再有偶数表示稳定版，奇数表示测试版的说法了。
那最重要的呢就是我们需要知道我们当前环境使用的内核版本，可以直接通过以下方式查看。
查看完整的内核版本信息 ➜ uname -a Linux matrix-cloud-storage-pro-97338-8gu60 3.10.0-957.21.3.el7.x86_64 #1 SMP Tue Jun 18 16:35:19 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux ➜ cat /proc/version Linux version 3.10.0-957.21.3.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC) ) #1 SMP Tue Jun 18 16:35:19 UTC 2019 只查看内核版本号 ➜ uname -r 3.</description>
    </item>
    
    <item>
      <title>TCP丢包不重传问题排查</title>
      <link>https://yesphet.github.io/posts/tcp%E4%B8%A2%E5%8C%85%E4%B8%8D%E9%87%8D%E4%BC%A0%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</link>
      <pubDate>Thu, 19 Mar 2020 14:59:19 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/tcp%E4%B8%A2%E5%8C%85%E4%B8%8D%E9%87%8D%E4%BC%A0%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</guid>
      <description>一、背景 前段时间，我们将私有云存储内容迁移到了某公有云存储，由于协议不兼容的原因，我们在业务及公有云存储中间搭建了一层代理服务做协议转换。在流量切换之后，发现约有0.05%的请求出现读内容超时的情况。大致表现就是对于一些下载请求，代理服务响应了Header 200，但在传输body的时候，出现了超时。
二、抓包分析 通过在代理服务（服务端）和负载均衡层Ingress（客户端）抓包发现，主要的问题是对于一些丢包，服务端没有进行重传（Retransmission）导致最后客户端一直没有收到完整的包直到超时。具体抓包如下：
从以下客户端抓包可以看到，客户端没有收到 [2711665,2719857] 这个包，因此一直在对 2711665进行ack，而服务端确实有收到大量的Duplicate ACK ack 2711665，但问题是为什么没有触发服务端的快速重传呢？ 查看 /proc/sys/net/ipv4/tcp_reordering 的值为3，所以可以确认服务端是有开启快速重传的，在收到3次duplicate ACK后就应该进行快重传，但从抓包文件中并没有发现有触发快速重传。
客户端抓包： 服务端抓包： 再通过 nstat 发现TcpExtTcpWqueueTooBig值较为异常
通过google搜索TcpExtTcpWqueueTooBig这个关键字，发现 Adventures in the TCP stack: Uncovering performance regressions in the TCP SACKs vulnerability fixes 这篇博文描述的问题和我们所遇到的基本一致。查看服务端内核版本为 3.10.0-957.21.3.el7.x86_64，再通过查看内核Changelog发现该版本正是刚好打完CVE-2019-11477, CVE-2019-11478 &amp;amp; CVE-2019-11479 这三个补丁
之后通过升级内核版本至  3.10.0-1062.1.1.el7.x86_64 后发现问题得到了解决。
三、问题分析 TCP SACK PANIC - Kernel vulnerabilities - CVE-2019-11477, CVE-2019-11478 &amp;amp; CVE-2019-11479 这三个补丁是为了解决SACK的安全问题。 在函数 tcp_fragment 中新增了如下代码
if (unlikely((sk-&amp;gt;sk_wmem_queued &amp;gt;&amp;gt; 1) &amp;gt; sk-&amp;gt;sk_sndbuf)) { NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPWQUEUETOOBIG); return -ENOMEM; } 从重传代码中发现当socket buffer长度大于MSS（最大报文长度）时，会先执行函数tcp_fragment，当以上代码if模块为true时，则会导致重传被中断，表现也就是我们上面抓包看到的收到了3次Duplicate ACK，却没有进行Retransmission的情况。更加具体的分析可以查看这篇博文Adventures in the TCP stack: Uncovering performance regressions in the TCP SACKs vulnerability fixes</description>
    </item>
    
    <item>
      <title>Redis学习笔记</title>
      <link>https://yesphet.github.io/posts/study-notes/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Thu, 12 Sep 2019 10:11:42 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/study-notes/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>Most of the contents of this note are excerpted from the Redis official documentation. It is recommended to read the official documentation directly if you want to learn Redis.
Redis data types  An introduction to Redis data types and abstractions
 Data structures supported by Redis:  Binary-safe strings Lists: collections of string elements sorted according to the order of insertion. They are basically linked lists. Sets: collections of unique, unsorted string elements.</description>
    </item>
    
    <item>
      <title>Time Series Database</title>
      <link>https://yesphet.github.io/posts/time-series-database/</link>
      <pubDate>Mon, 15 Jul 2019 17:07:35 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/time-series-database/</guid>
      <description>一、Feature Comparison  Survey and Comparison of Open Source Time Series Databases
 TSDB 的分组  依赖其他DBMS（如Cassandra，HBase，CouchDB，MySQL）来存储time series数据的。该分组不包括使用其他DBMS来存储meta信息的TSDB。 不依赖其他DBMS来存储time series数据的。 可以存储time series数据的RDBMS 非开源的TSDB  TSDB 对比 从 Survey and Comparison of Open Source Time Series Databases 中提取关于 InfluxDB、Prometheus、Druid、OpenTSDB的对比。这篇Paper主要是对各个TSDB进行定义和分类，以及对比比较流行的前12个TSDBs的特性。以下摘取其中比较值得注意的对比。更详细的请参考原文。
✓ means available (✓) means available with restrictions
✗ means not available
1、Criteria Group 1: Distribution/Clusterability.    TSDB High Avaliable Scalability Load Balancing remark     OpenTSDB ✓ (✓) (✓) 部署多个HBase节点，通过DNS或者HaProxy等lb将query分布到不同的实例   Druid ✓ ✓ ✓ Druid 使用RDBMS作为元数据存储，zookeeper作为协调，以及分布式存储（HDFS/S3/Azure）来保存数据，需要部署5个不同类型的节点。   InfluxDB ✓ ✗ （企业版才支持） ✓ 通过 influxDB-relay 来实现高可用和负载均衡   Prometheus ✗ (✓) (✓) Can Prometheus be made highly available?</description>
    </item>
    
    <item>
      <title>How To Read</title>
      <link>https://yesphet.github.io/posts/how-to-read/</link>
      <pubDate>Fri, 12 Jul 2019 10:37:47 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/how-to-read/</guid>
      <description>How to Read a Paper  How to Read a Paper
 三步阅读法 （Three-pass approach） 第一步（first-pass） 快速浏览整篇论文，同时决定是否需要继续阅读该文章。这一步一般花费5-10分钟完成以下事情：
 仔细阅读标题、摘要和介绍 阅读章节和子章节的标题，忽略其他内容 阅读结论 浏览引用，在心中标出你已经阅读过原文的引用。  在完成第一步后，你需要能回答以下五个内容：
 分类（Category）： 这篇论文的类型是什么？ 上下文 （Context）：这篇论文有哪些关联的其他论文？这篇论文使用了哪些理论依据来分析问题？ 正确性（Correctness）：论文中的假想是否成立？ 贡献（Contributions）：论文的主要贡献？ 澄清（Clarify）：论文是否写的好？  根据这些内容，你可以选择是否继续阅读。
第二步 （second-pass） 第二步，仔细阅读论文，但是忽略一些例如证明的细节。阅读的时候对关键点做一些笔记或在边缘做一些评论是会有帮助的。
 仔细阅读论文中的图形、图表和插图。尤其关注曲线图，轴线是否有恰当的标签？结果是否标记错误，导致结论有统计显著性（statistically significant）? 这些常见的错误可以用来区分论文是赶工的还是真正优秀的 记得标注未曾读过的引用，在之后进行阅读。这可以很好的帮助学习这篇论文相关的背景。  第二步花费一个小时。在这一步之后，你需要能理解这篇论文的内容，并能总结文章的主旨用来向其他人证明。对于你感兴趣的论文，此时你的理解程度已经可以满足，但对于你的专业研究，此时的理解还不足够。
有时你完成第二步后仍然无法理解这篇论文。这可能是因为你对论文的主题比较陌生，对论文中的术语、缩写不熟悉。或者作者使用了一些你不明白的证明或试验技术，导致文章的大部分内容难以理解。或者论文不严谨的使用未证实的定理或者指向大量的引用。或者可能只是时间太晚你觉得疲倦了。这个时候，你可以选择：
 把这篇论文放在一边，祈祷在你的职业中不需要理解这些材料。 在阅读相关的背景材料之后再回来阅读这篇论文。 坚持进行第三步  第三步（third-pass） 为了完整理解一篇论文，尤其当你是审稿员时，需要进行第三步。第三步的关键是在虚拟中尝试重新实现这篇论文：和作者做同样的假设，重新构建工作。 通过对比你的重构和原文，你可以轻易的验证文章的创新，发现其中隐藏的缺点和假想。
这一步需要花费很多的注意力在细节上。你需要验证和质疑每一段话中的每个假想。除此之外，你需要思考你自己会提出什么样特别的观点。这种实际和虚拟的对比给予你对论文中的证明和技术强烈的洞察力，你可以轻易的把这些加入你的工具储备。在这一步中，你同样需要记下每一个观点用于以后的工作。
这一步对于初学者会占用大概四到五个小时，对于有经验的读者只需要大约一个小时。在这一步的最后，你需要可以在记忆中重建这篇论文的结构，同时也可以验证它的优缺点。特别的，你需要能精确的指出其中暗藏的假设，缺少的引用，和实验技术中潜在的问题。
文献调研 论文阅读技巧可以在文献调研中得到检验。文献调研需要你阅读数十篇论文，可能是在你不熟悉的领域。那么你需要阅读哪些论文呢？
首先，通过学术搜索引擎例如Google Scholar或者CiteSeer和一些精选的关键词，找到3-5篇该领域最新的论文。先对每一篇文章完成第一步（first-pass）来获得对该领域一个初步的认识，然后阅读这些论文相关的章节。你会找到一个对于该领域大概的总结。如果你足够幸运，可能可以找到一个该领域的调查报告，阅读该调查报告即可。
然后，在这些论文的参考文献列表中，找到相同的引用文献和重复的作者名字。这些是该领域的关键论文和研究者。下载这些文献放在一旁。然后到这些研究者的网站中看看他们最近在那些地方做了发表。这可以帮助你确认这个领域最顶级的会议。因为最好的研究者经常会在顶级会议做发表。
最后，到这些顶级会议的网站中查看他们最近的进程。快速的浏览可以帮助确认该领域最新相关的高质量成果。这些成果连同之前下载的文献，可以组成你第一个版本的调研。然后通过第二步（second-pass）阅读这些文章。如果这些文章都引用了相同的你之前没有找到的文献，那么就获取并阅读该文献，以此迭代。</description>
    </item>
    
    <item>
      <title>Serverless and Faas</title>
      <link>https://yesphet.github.io/posts/faas-serverless/</link>
      <pubDate>Thu, 21 Feb 2019 15:05:35 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/faas-serverless/</guid>
      <description>一、Serverless/Faas 什么是Serverless？在云时代，简单的说就是服务器对开发者是透明的 。当然并不仅是这么简单，只是我认为在还不能完全做到服务器对开发者透明的时候，探讨Severless更多的含义是没有太大意义的。因为无论是什么技术的出现，其目的都是为了提高生产效率。在计算机领域，提高生产效率的方式有很多种，降低程序员的心智负担，降低开发门槛是其中非常重要的一种，毕竟现在还是以人为本的时代。而Severless很重要的一个能力便是极大极大地减轻开发人员的负担，更简单的说便是极大地减少每一个项目的代码量。
作为一个菜鸡，我没有资格探讨什么计算机的前世今生。但就像汇编语言让机器语言变成透明，高级语言让汇编语言变成透明一样，Serverless可以让服务器逐渐变得透明。服务端开发人员不再必须明白操作系统、计算机网络等底层内容就能够很好地开发维护和使用一个服务，就像现在的程序员已经不再必须明白电路信号就能开始写代码一样。
这是我认知的Serverless，但我一直还觉得Serverless远不只于此。
那什么是Function as a Service（Faas）呢，我认同Faas是Serverless的一种实现。通过Faas，开发人员只需要专注于业务代码，不需要去关心服务器环境之类，自然服务器对开发者就是透明的。当然Serverless还有许多其他的实现，例如云存储（AWS的S3/阿里云的OSS）就是Serverless在存储系统上的一种实现。
有了Faas，程序员开发上线一个Hello World服务，就真的只要在代码里写下Hello World，就有了Hello World这个服务了。不需要关心服务器在哪里，怎么配置搭建环境，怎么打包发布。甚至当你写了Hello World这些代码发布成服务后，你不需要任何操作就可以直接获得这个服务的监控，比如多少访问QPS、成功率多少、响应时间多少，当成功率低于多少时你便会收到报警。这些所有的配套设施Faas都帮你做了，这就是Faas的魅力，是非常切实地在提升生产效率。
在物理机时代，只有优秀的程序员，可以掌握从设计到架构，从开发到上线，可以精准地定位解决问题，不单是程序的，还包括各个层面导致的问题。而通过Faas，不那么优秀的程序员，也可以做到和优秀程序员一样的事了。这是一本秘籍，一本化繁为简的秘籍。不需要那么多的架构设计，我只需要关注并设计好这个小小的Function，没有那么多问题需要排查了，就这几十几百行的代码能有多少问题呢？Faas平台有缺陷，有漏洞？那是Faas维护者的事，反馈就完事了。就像现在有多少程序员能真的帮忙解决修复操作系统的缺陷呢？而优秀的程序员，也不再需要被业务缠身，轻松完成开发上线，从而有更多的精力投身更多的建设。
当然，现在的Faas已经远不止我说的这些。它还有许多优秀的特性，我们继续分析。
二、Faas的特性 现在，Faas已经从边缘走向了中心，越来越频繁地出现在技术人员的视线中。其具有最明显的优势是：
 按需计算 简化开发 事件驱动 小巧灵活  2.1 按需计算 Faas是真正的按需计算，这些计算任务需要多少资源，就给你多少资源。
在离线任务的场景下，这很好实现，因为一开始我就知道有多少计算任务，需要多少计算资源。但在在线任务场景下呢？谁也不知道下一个流量峰刺什么时候到来。在物理机时代，大家只能按照经验准备足够的物理机冗余。在云主机时代，也需要提前扩容VPS，这些不得不的冗余虽然一定程度保障了服务的安全，但同时也造成了资源的浪费，这是资源等待请求的模式。而Faas，通过毫秒级别的冷启动时间，并不需要提前启动好资源等待请求。而是可以等请求到来的时候，让请求等待资源启动，然后进行计算，计算完成后释放计算资源。这是请求等待资源的模式，是完全按需的。这个等待时间是极短的。可能有些业务场景容忍不了这额外带来的毫秒级别的等待，但faas依然可以通过极少的资源冗余和弹性伸缩去解决这些等待时间，让请求几乎无感知等待耗时。
弹性伸缩便是通过各项指标，来预测资源冗余是否充足或过多，从而提前自动扩容缩容。这些指标简单可以是CPU使用率、Load值、内存使用率等资源指标，但这样的指标其实已经稍微偏离了业务，并不能达到非常准确的预测。更高级地可以通过业务QPS的增长率等贴近业务的指标来作为判断依据，更为准确，也更专注于业务。
通过这种真正的按需计算，也可以真正达到cost-efficient，high utilization的目标。
2.2 简化开发 如第一部分说的，在Faas下，开发人员只需要专注在业务代码中，编程模型得到了极大的简化。除此之外，还将很多事情让渡给了云。例如2.1中说的弹性伸缩，其实在物理机、云主机模式下也可以实现，但在这些模式下，不够干净的隔离，只会给开发人员带来更多的心智负担。Faas还为开发人员完成许多想做但又可能没有精力做的事情，例如完善的监控于报警系统等等。
2.3 事件驱动 现在很多Faas实现的协议都是遵循事件驱动的。也就是除了普通的Http请求、消费消息队列，还有许多的方式去触发计算，例如文件上传到云存储，可以自动触发内容识别、审核、分类的Function。这也简化许多业务的流程。
2.4 小巧灵活 在Faas下，期望的是能做到足够的解耦，每个Function都足够的小，因此能运行在许许多多的计算资源上。通常情况下我们认知的计算资源就是服务器，但其实除了专用服务器，还有很多很多计算资源没有被好好利用。例如CDN的边缘节点、IoT中许多空闲的智能设备。Faas为利用这些资源带来了可能，因为一定有足够小的Function，小到可以用这些轻量设备就完成计算。并且这些设备协议通常也都遵循事件驱动的方式。这也是边缘计算的可能。
三、Faas的实现 目前开源的Faas项目已经有许多，其中我较为熟悉的是fission、kubeless，可以参考适用于多媒体云处理的faas实现。
//TODO 补充Faas的实现思路
四、相关资料  Serverless/FaaS 的现状和未来 Report from workshop and panel on the Status of Serverless Computing and Function-as-a-Service(FaaS) in Industry and Research FaaS 如何在云 2.0 时代发挥优势，又将走向何方？ Serverless 应用开发指南  </description>
    </item>
    
    <item>
      <title>Blog从Jekyll迁移至Hugo</title>
      <link>https://yesphet.github.io/posts/blog%E4%BB%8Ejekyll%E8%BF%81%E7%A7%BB%E8%87%B3hugo/</link>
      <pubDate>Tue, 19 Feb 2019 17:55:49 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/blog%E4%BB%8Ejekyll%E8%BF%81%E7%A7%BB%E8%87%B3hugo/</guid>
      <description>一、背景 很久没有更新博客了，年后打算重新收拾一下。之前使用的是Jekyll，但是依赖管理什么的实在是太麻烦了，因此打算更换一个框架。刚好了解到Hugo是用Golang写的，所以就准备将博客从Jekyll迁移到Hugo。 现在迁移基本完成了，过程还是踩了蛮多坑的，所以顺便写一篇记录一下，防止以后要改改改的时候又重新踩坑。
二、方案 这次使用的hugo版本是：
Hugo Static Site Generator v0.54.0/extended darwin/amd64 BuildDate: unknown 安装姿势随便搜一下就有了。
2.1 直接使用hugo cli工具 ➜ hugo import --help Import your site from other web site generators like Jekyll. Import requires a subcommand, e.g. `hugo import jekyll jekyll_root_path target_path`. Usage: hugo import [command] Available Commands: jekyll hugo import from Jekyll Flags: -h, --help help for import Global Flags: --config string config file (default is path/config.yaml|json|toml) --configDir string config dir (default &amp;#34;config&amp;#34;) --debug debug output --log enable Logging --logFile string log File path (if set, logging enabled automatically) --quiet build in quiet mode -v, --verbose verbose output --verboseLog verbose logging Use &amp;#34;hugo import [command] --help&amp;#34; for more information about a command.</description>
    </item>
    
    <item>
      <title>计算密集型服务部署于k8s压力测试总结</title>
      <link>https://yesphet.github.io/posts/%E8%AE%A1%E7%AE%97%E5%AF%86%E9%9B%86%E5%9E%8B%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2%E4%BA%8Ek8s%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E6%80%BB%E7%BB%93/</link>
      <pubDate>Tue, 13 Nov 2018 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/%E8%AE%A1%E7%AE%97%E5%AF%86%E9%9B%86%E5%9E%8B%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2%E4%BA%8Ek8s%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E6%80%BB%E7%BB%93/</guid>
      <description>一、背景 二、知识点 2.1 k8s中容器资源的分配与管理  request 与 limit  //TODO
2.2 docker中，使用cgroup进行资源隔离  cpuset  //TODO
三、参考 NUMA架构的CPU &amp;ndash; 你真的用好了么？
[Control CPU Management Policies on the Node
 Kubernetes](https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/)  </description>
    </item>
    
    <item>
      <title>分布式异步回调模型的回调策略</title>
      <link>https://yesphet.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BC%82%E6%AD%A5%E5%9B%9E%E8%B0%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9B%9E%E8%B0%83%E7%AD%96%E7%95%A5/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BC%82%E6%AD%A5%E5%9B%9E%E8%B0%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9B%9E%E8%B0%83%E7%AD%96%E7%95%A5/</guid>
      <description>一、背景 客户端请求Web服务架构中，一般有同步阻塞模型和异步回调两种模型。对于服务端耗时较长，例如音视频转码等重操作的服务，异步回调模型相比同步模型有许多的优势:
 不会阻塞客户端的请求线程，可以提高客户端的线程利用率。 服务端根据自身的处理能力进行处理，保证服务端的稳定性。不会由于峰值请求造成服务端过载。  但是，在异步回调模型中，由于多了一次回调的链路，会带来更多的可用性问题。因此，本文主要讨论在异步回调模型中，如何制定有效的回调策略来保证回调链路的成功率，并提高整个异步服务的可用性。
二、异步回调模型 异步回调模型可以参考引用1中的描述，一般有以下两种细分模型：
2.1 Asynchronous Web Service Using a Single Request Queue 2.2 Asynchronous Web Service Using a Request and a Response Queue 其中2.2的模型虽然更复杂，但可以有效的提高服务端的资源使用率。避免由于回调阻塞导致处理能力的下降。同时可以增加一些判重策略，防止回调服务出现故障时，由于客户端重试导致服务端重复处理的资源浪费。
在分布式服务场景下，2.2 模型还可以细分为Inner Response Queue及outer Response Queue两种：
 Inner Response Queue为每个服务端app使用内存队列作为Response Queue，由内部的线程作为Callback Client。 Outer Response Queue为使用统一的消息队列中间件作为Response Queue，另外部署一套Callback Client服务来处理这些Response。  Outer模型相比Inner模型部署结构较为复杂，但与处理结构完全解耦，可以针对回调做更多策略，同时可以防止由于处理app宕机造成的Response丢失（不过由于callback client以及消息中间件策略的问题，仍然会存在response丢失的风险）。
以上各个模型各有优劣，应该根据业务场景选择合适的模型。
三、回调策略 对于异步回调模型，callback service一般由业务方提供，无法对可用性做保证。因此callback client必须要制定一些策略尽量的应对callback service失败的情况。尤其是在一个callback client对应多个callback service的场景下，需要尽量防止由于某些service的问题，影响回调其他service的情况。
Callback Service 失败场景： 1. client与service之间出现网络波动，甚至中断。 callback client请求service时，响应域名解析失败或者client请求超时。
快速重试策略可以解决网络波动问题。轮询重试策略可以解决短时间中断问题。
2. service超时。 callback service处理回调超时。这种情况除去网络问题，一般是由于service负载过高，或者设计存在问题导致。这种场景如果过度重试一般会造成service雪崩。解决的方案是周知业务方，由业务方对callback service进行排查。</description>
    </item>
    
    <item>
      <title>动态查找树</title>
      <link>https://yesphet.github.io/posts/%E5%B9%B3%E8%A1%A1%E6%A0%91/</link>
      <pubDate>Wed, 18 Jul 2018 16:10:58 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/%E5%B9%B3%E8%A1%A1%E6%A0%91/</guid>
      <description>一、二叉查找树 二叉查找树是比较基础的一种结构，我一般比较习惯叫它排序二叉树或堆排。具体的定义可以参考 维基百科
对于一棵排序二叉树，主要有以下几个操作：
   操作 时间复杂度     查找 时间复杂度等于树高，期望是 $O(log n)$，最差情况是 $O(n)$，即树退化成了链表   插入 复杂度和查找相同，先查找到新元素的位置，再 $O(1)$ 插入即可   删除 复杂度和查找相同，先查找到元素的位置，再 $O(1)$ 删除即可    作为堆排，其时间复杂度是 $O(n log n)$ ，即n次插入操作。之后再进行一次中序遍历即可输出排序好的数列。
源码实现： https://github.com/yak2p/trees/tree/master/binary-search-tree
二、平衡二叉树 1、什么是平衡树 平衡树是对二叉查找树的一种改进。目的是通过平衡树的左右子树，使所有叶子节点的深度趋于平衡，即树高等于 $O(log n)$。以此使查找的复杂度尽量趋近于 $O(log n)$。 具体的定义还是参考维基百科
平衡二叉树的定义如下：
 左右子树的高度差小于等于 1。 每一个子树均为平衡二叉树。  2、AVL树 AVL树是最早被发明的自旋平衡二叉查找树。在AVL树中，任一节点对应的两棵子树的最大高度差为1，因此它也被称为高度平衡树。查找、插入和删除在平均和最坏情况下的时间复杂度都是 $O(log n)$
AVL树的实现是通过记录平衡因子（Balance Factor）来判断树是否平衡。
 平衡因子： 左子树的高度减去它的右子树的高度
 当一个节点的平衡因子不为 -1、0、1时，即该节点的左子树和右子树的高度差超过1，则认为以该节点为根的子树不平衡。
当插入和删除一个节点之前，我们认为树总是平衡的。
当插入和删除一个节点之后，如果导致树变得不平衡，则通过旋转操作来将树重新平衡。
因此，对于AVL树，在任何时刻，平衡因子的绝对值不可能&amp;gt;2。
3.1 旋转 3.</description>
    </item>
    
    <item>
      <title>适用于多媒体云处理的Faas实现</title>
      <link>https://yesphet.github.io/posts/%E9%80%82%E7%94%A8%E4%BA%8E%E5%A4%9A%E5%AA%92%E4%BD%93%E4%BA%91%E5%A4%84%E7%90%86%E7%9A%84faas%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Thu, 21 Jun 2018 15:17:43 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/%E9%80%82%E7%94%A8%E4%BA%8E%E5%A4%9A%E5%AA%92%E4%BD%93%E4%BA%91%E5%A4%84%E7%90%86%E7%9A%84faas%E5%AE%9E%E7%8E%B0/</guid>
      <description>一、背景 云处理平台，是公司基于私有云存储打造的一个针对图片、视频进行格式转换、裁剪、转码以及许多自定义操作的平台，类似于七牛云的多媒体API、阿里云的智能媒体管理。全量支持了公司所有图片及视频的处理。
最早的时候，云处理平台和云存储是一起诞生的，是作为云存储的一个子项目，在同一套系统中实现。虽然部署的时候是按照上传、下载、处理分集群进行部署，但是随着功能性的提升，项目代码越来越复杂，部署的成本也逐渐升高。因此我们进行了第一次重写，将其独立了开来，但仍旧是使用Java+Tomcat的方式部署在物理机上。
2018年初，随着业务的发展，云处理平台遇到了许多瓶颈和痛点。其中最为明显的是：
 新增一个处理接口的成本过高，这里的成本主要指上线及部署成本，需要由运维同学发布到每一台处理集群的物理机（那时我们已经实现了新增一个处理接口只需要编写处理脚本即可，不需要改动到Java代码，类似于Faas中的 『开发人员只需要关注功能代码的开发』 ）。 集群难以继续细分。由于面对公司很多产品，每个产品使用的处理接口不尽相同，且各接口的复杂度差异也很大（例如视频转码接口耗时是十秒级别，而大部分图片处理接口耗时是百毫秒级别）。由于都是重CPU操作，因此当集群负载高时，各接口可能互相影响，导致响应时间变慢。 云处理平台只支持同步请求，异步处理的方式是通过部署一个队列处理机来消费队列，解析队列中的消息再通过Http请求云处理平台，得到处理结果后，再回调业务方。整个流程变长，增加了部署管理成本，也更加的不可控。 集群扩容缩容麻烦。当业务上要进行推广时，只能由运维手动加入机器到集群，部署云处理服务，缩容也是一样。虽然后来有了自助上线平台，但成本依然较高，部署耗时长，风险大。 机器使用率无法很好的利用。由于是物理机部署，扩容缩容成本高，因此为了服务的可用性，必须要保证集群有较多的冗余，防止峰值流量将集群打垮的情况。 &amp;hellip;  适时正好Faas非常流行，公司也正在推进容器化，因此我们便又进行了新的一次重构，以Faas的思想实现了目前的云处理平台。
二、前期调研 前期调研了 fission 和 kubeless 两个开源的faas项目。两者都是基于k8s实现。调研时，fission的实现更为完善一些，所以侧重看了一些fission的源码。
fission的实现是通过trigger层来接受event，再通过http请求router层映射到对应的function，获取或启动对应的pod来处理这个event。其中trigger层类似于http服务器，或者队列处理机，router层担任的角色类似于API网关。而function层则是真正执行任务的地方，其事先由poolManager根据不同environment（go/binary/python&amp;hellip;）启动pod，pod对router层暴露http端口。当router层收到一个event时，根据url映射到对应function，再找到可以处理该event的pod（如果没有则立即创建，冷启动时间为100ms，pod启动时是没有function代码的，需要到etcd中拉取function代码，因此也限制了代码的大小必须在1MB内），最后将event通过http请求到可以执行的pod中。
那么fission适合我们云处理平台的场景吗？其实并不契合的。主要有几点：
 代码大小的限制，由于云处理除了一些简单的脚本外，有的脚本还需要依赖一些素材等资源文件，这些都属于function的一部分，这些的体积基本都会&amp;gt;1MB。 function pod统一暴露的都是http服务，虽然trigger层有支持mqtrigger（类似于队列处理机），但一些视频转码的请求一般需要几十秒甚至分钟级别，通过保持http连接进行通信不够可靠。 function代码是pod启动的时候临时拉取的。同第一点，云处理的function体积较大，启动时再拉取一个是影响冷启动时间，一个是会对带宽造成额外压力。  不是fission不好，而是因为云处理本身的场景就不在fission的考虑范围内，fission更倾向于支持的是小型、快速、生命周期短的function，例如一些解耦的非常干净的http处理函数。这也是AWS Lambda中的主要业务形态。
通过fission，我们也大概明白了faas的实现方式，参考了许多设计的方式，并实现了云处理平台的Faas系统 &amp;ndash; Trident 和 Poseidon。
其中Trident是函数管理系统，类似于fission中的controller。用于管理函数，发布服务，弹性扩缩容（HPA）。
Poseidon 则是运行时，包含trigger，environment，function等运行模块。本文也会着重介绍Poseidon
三、Poseidon 3.1 基本结构 Poseidon 的基本结构如下：
1. Trigger trigger层作为最上层，直接与前端交互，负责前端消息的接受和响应。这边的前端消息是指例如Http Request、消息队列中的消息。前端响应指例如Http Response、回调等。 目前Trigger层有4种实现：
 Http Server Kaproxy Consumer Kafka Consumer Command Line Interface  2. Protocol protocol层负责对前端消息的内容进行解析，构造成标准输入。将标准输入传递给Controller层进行下一步处理，之后解析Controller层响应的标准输出，构造成Trigger层的响应并返回给Trigger层。
Protocol interface { // 解析Http Request，并传递给Controller层处理。将处理结果转换为response返回 HttpParse(ctx context.</description>
    </item>
    
    <item>
      <title>编译安装gcc5.3</title>
      <link>https://yesphet.github.io/posts/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85gcc5.3.0/</link>
      <pubDate>Tue, 22 May 2018 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85gcc5.3.0/</guid>
      <description>安装命令 ## 准备安装到的目录 export GCC5.3.0_BASE=/usr/local/gcc5.3.0 ## install gmp4.3.2 wget ftp://gcc.gnu.org/pub/gcc/infrastructure/gmp-4.3.2.tar.bz2 tar jxvf gmp-4.3.2.tar.bz2 cd gmp-4.3.2 ./configure --prefix=$GCC5.3.0_BASE make &amp;amp;&amp;amp; make install ## install mptr wget ftp://gcc.gnu.org/pub/gcc/infrastructure/mpfr-2.4.2.tar.bz2 tar jxvf mpfr-2.4.2.tar.bz2 cd mpfr-2.4.2 ./configure --prefix=$GCC5.3.0_BASE --with-gmp=$GCC5.3.0_BASE make &amp;amp;&amp;amp; make install ## install wget ftp://gcc.gnu.org/pub/gcc/infrastructure/mpc-0.8.1.tar.gz tar xvzf mpc-0.8.1.tar.gz cd mpc-0.8.1 ./configure --prefix=$GCC5.3.0_BASE --with-gmp=$GCC5.3.0_BASE --with-mpfr=$GCC5.3.0_BASE make &amp;amp;&amp;amp; make install ## install gcc5.3.0 wget http://ftp.gnu.org/gnu/gcc/gcc-5.3.0/gcc-5.3.0.tar.gz tar xvzf gcc-5.3.0.tar.gz cd gcc-5.3.0 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$GCC5.3.0_BASE/lib ./configure --prefix=$GCC5.3.0_BASE --with-gmp=$GCC5.3.0_BASE --with-mpfr=$GCC5.</description>
    </item>
    
    <item>
      <title>FFmpeg安装</title>
      <link>https://yesphet.github.io/posts/ffmpeg%E5%AE%89%E8%A3%85/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/ffmpeg%E5%AE%89%E8%A3%85/</guid>
      <description>编译参数 export FF_BUILD=$HOME/ffmpeg3.4.1_build export FF_INCLUDE=$FF_BUILD/include export FF_LIB=$FF_BUILD/lib export FF_BIN=$FF_BUILD/bin export PATH=$FF_BIN:$PATH fdk_aac cd /tmp/ffmpeg_source git clone --depth 1 git://git.code.sf.net/p/opencore-amr/fdk-aac cd fdk-aac autoreconf -fiv ./configure --prefix=&amp;quot;$FF_BUILD&amp;quot; --disable-shared make &amp;amp;&amp;amp; make install &amp;amp;&amp;amp; make distclean libmp3lame cd /tmp/ffmpeg_source wget http://iweb.dl.sourceforge.net/project/lame/lame/3.99/lame-3.99.5.tar.gz tar zxf lame-3.99.5.tar.gz cd lame-3.99.5 ./configure --prefix=&amp;quot;$FF_BUILD&amp;quot; --bindir=&amp;quot;$FF_BIN&amp;quot; --enable-shared --enable-nasm make &amp;amp;&amp;amp; make install &amp;amp;&amp;amp; make distclean yasm cd /tmp/ffmpeg_source git clone --depth 1 git://github.com/yasm/yasm.git cd yasm autoreconf -fiv ./configure --prefix=&amp;quot;$FF_BUILD&amp;quot; --bindir=&amp;quot;$FF_BIN&amp;quot; make &amp;amp;&amp;amp; make install &amp;amp;&amp;amp; make distclean nasm cd /tmp/ffmpeg_source wget http://www.</description>
    </item>
    
    <item>
      <title>ImageMagick安装</title>
      <link>https://yesphet.github.io/posts/imagemagick%E5%AE%89%E8%A3%85/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/imagemagick%E5%AE%89%E8%A3%85/</guid>
      <description>由于工作需求，一直有需要使用ImageMagick和FFmpeg等多媒体处理软件做一些简单的需求。这两个项目的依赖较多，且针对不同的需求，可能需要开启不同的功能，安装较为麻烦。因此在此做下一些相关安装的记录，避免之后的重复学习。
Centos 1、直接安装 yum install imageMagick 很粗暴，但是由于yum源更新较慢，版本一般较低。所以不建议这种方式。
2、源码安装 安装delegates yum install libjpg libjpg-devel libpng libpng libwebp libwebp-devel libxml2 libxml2-devel fontconfig fontconfig-devel libtiff libtiff-devel freetype freetype-devel zlib zlib-devel jasper jasper-devel  参考 官网文档
 wget https://www.imagemagick.org/download/ImageMagick.tar.gz tar xvzf ImageMagick.tar.gz cd ImageMagick-7.0.7-28/ ./configure --enable-hdri make sudo make install sudo ldconfig /usr/local/lib convert -version 建议采用这种姿势，可以比较自用的配置安装项。
Mac OS X 1、 brew安装 brew install imagemagick 也是简单粗暴，但brew源更新的速度就很快，一般都可以安装到近期的ImageMagick的版本。因此建议采用这种方式，省心。
brew info imagemagick 也可以通过info查看安装选项，灰常方便。</description>
    </item>
    
    <item>
      <title>FFmpeg学习笔记</title>
      <link>https://yesphet.github.io/posts/study-notes/ffmpeg%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 12 Sep 2017 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/study-notes/ffmpeg%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>查看视频信息 使用ffprobe
 文档： https://ffmpeg.org/ffprobe.html
 插入关键帧 -force_key_frames 
一般使用expr:expr方式来指定:
 If the argument is prefixed with expr:, the string expr is interpreted like an expression and is evaluated for each frame. A key frame is forced in case the evaluation is non-zero.
  文档： https://ffmpeg.org/ffmpeg.html
expr函数可以参考： https://ffmpeg.org/ffmpeg-all.html#Expression-Evaluation
 视频分割 ffmpeg -i 4M.mp4 -codec:v h264 -codec:a copy \  -force_key_frames &amp;#39;expr:if(isnan(prev_forced_t),gte(t,0),gte(t,prev_forced_t+5))&amp;#39; \  -f segment -segment_list test.ffcat -segment_times 5,10 -segment_time_delta 1 out%03d.</description>
    </item>
    
    <item>
      <title>Tomcat7压测(2)</title>
      <link>https://yesphet.github.io/posts/tomcat7%E5%8E%8B%E6%B5%8B2/</link>
      <pubDate>Tue, 14 Feb 2017 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/tomcat7%E5%8E%8B%E6%B5%8B2/</guid>
      <description>目的  本篇将请求的耗时调大，主要为了观察线程池及等待队列都满了的情况下，Tomcat的表现及反应。  初步压测描述 先描述下一开始进行这部分压测遇到的问题。首先根据Tomcat7官方文档描述：
 Each incoming request requires a thread for the duration of that request. If more simultaneous requests are received than can be handled by the currently available request processing threads, additional threads will be created up to the configured maximum (the value of the maxThreads attribute). If still more simultaneous requests are received, they are stacked up inside the server socket created by the Connector, up to the configured maximum (the value of the acceptCount attribute).</description>
    </item>
    
    <item>
      <title>Tomcat7压测(1)</title>
      <link>https://yesphet.github.io/posts/tomcat7%E5%8E%8B%E6%B5%8B1/</link>
      <pubDate>Wed, 08 Feb 2017 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/tomcat7%E5%8E%8B%E6%B5%8B1/</guid>
      <description>Tomcat7压测（一） 目的   目的主要有几点：
 了解空跑的TomcatQPS能达到多少 测试在Tomcat线程池，等待队列，最大连接数满了的情况下Tomcat的表现 通过压测暴露一些问题及对这些问题的解决 提升性能测试的姿势，算是一种锻炼吧    应该会分几个篇幅来分析，因为压测场景及数据比较多。
  本篇主要是最基础的测试，后续会对压测中发现的问题做一些解决
  压测 场景           Tomcat配置 maxThreads=&amp;quot;300&amp;quot;minSpareThreads=&amp;quot;100&amp;quot;connectionTimeout=&amp;quot;8000&amp;quot;enableLookups=&amp;quot;false&amp;quot;acceptCount=&amp;quot;100&amp;quot;acceptorThreadCount=&amp;quot;1&amp;rdquo;    环境 Docker容器内    服务描述 当收到一个请求后，将处理该请求的线程sleep20ms,然后返回response。因为该服务本身几乎不占用任何系统资源，所以在CPU，Mem，IO上是不会产生瓶颈的（实际压测证实），且因为该场景下控制了每个请求的耗时，QPS不高，所以在网络IO上也不会产生瓶颈。因此会影响QPS的只有Tomcat线程池的参数和Tomcat的性能    服务耗时 20ms     数据(整理后)    序号 API TotalTime Requests per second Time per request Tomcat线程池线程数 描述     1 ab -c100 -n500000 -k http://172.</description>
    </item>
    
    <item>
      <title>Java·多线程·并发学习笔记</title>
      <link>https://yesphet.github.io/posts/study-notes/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 06 Jan 2017 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/study-notes/java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>进程和线程  进程(Process)是指一次程序的运行。对于单核CPU来说，同一时间只能执行一个进程。单核CPU实现多任务的方式一般是每个进程轮流执行，任务1执行0.01秒，然后切换到任务2。。。多核CPU则可以真正意义上实现多个任务并发执行，但当任务数大于CPU核数时，也是采取轮流执行的方法。进程之间是相互独立的。 线程(Thread)则是存在于进程之内，一个进程内可以拥有多个线程，多个线程共享该进程的一切资源。 协程(Coroutine)，埋个坑。在较新的语言中，比如go，对协程应用较广。  非线程安全和线程安全  非线程安全指多个线程对同一个资源进行操作时，可能导致值不同步的情况。 线程安全指不会出现非线程安全问题。。。 - . -  Java中的Thread 一、 多线程的实现方法   继承Thread，重写run方法。
public class MyThread extends Thread{ @Override public void run() { } } 执行线程： new MyThread().start();   实现Runnable，传给Thread构造
public class MyRunnable implements Runnable{ public void run() { //执行内容  } } 调用方法： new Thread(new MyRunnable()).start(); 或者使用jdk1.8的lambda表达式: new Thread(()-&amp;gt;{ //执行内容  }).start();   二、线程的停止   线程停止的方法
   </description>
    </item>
    
    <item>
      <title>RFC3986</title>
      <link>https://yesphet.github.io/posts/rfc3986/</link>
      <pubDate>Tue, 15 Nov 2016 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/rfc3986/</guid>
      <description>预备知识  统一资源标识符（URI）
RFC3986中文文档
RFC3986英文文档
 RFC3986编码与解码   保留字符
Url可以划分成若干个组件，协议、主机、路径等。有一些字符（:/?#[]@）是用作分隔不同组件的。例如:冒号用于分隔协议和主机，/用于分隔主机和路径，?用于分隔路径和查询参数，等等。还有一些字符（!$&amp;amp;&#39;()*+,;=）用于在每个组件中起到分隔作用的，如=用于表示查询参数中的键值对，&amp;amp;符号用于分隔查询多个键值对。当组件中的普通数据包含这些特殊字符时，需要对其进行编码。
RFC3986中指定了以下字符为保留字符：
! * &#39; ( ) ; : @ &amp;amp; = + $ , / ? # [ ]   不安全字符
还有一些字符，当他们直接放在Url中的时候，可能会引起解析程序的歧义。这些字符被视为不安全字符，原因有很多。
   符号 描述     空格 Url在传输的过程，或者用户在排版的过程，或者文本处理程序在处理Url的过程，都有可能引入无关紧要的空格，或者将那些有意义的空格给去掉   引号以及&amp;lt;&amp;gt; 引号和尖括号通常用于在普通文本中起到分隔Url的作用   # 通常用于表示书签或者锚点   % 百分号本身用作对不安全字符进行编码时使用的特殊字符，因此本身需要编码   {} ^[]`~ 某一些网关或者传输代理会篡改这些字符|      对保留字符及不安全字符进行编码
Url编码通常也被称为百分号编码（Url Encoding，also known as percent-encoding），是因为它的编码方式非常简单，使用%百分号加上两位的字符——0123456789ABCDEF——代表一个字节的十六进制形式。Url编码默认使用的字符集是US-ASCII。例如a在US-ASCII码中对应的字节是0x61，那么Url编码之后得到的就是%61，我们在地址栏上输入http://g.</description>
    </item>
    
    <item>
      <title>CPU：物理核与逻辑核</title>
      <link>https://yesphet.github.io/posts/cpu%E7%89%A9%E7%90%86%E6%A0%B8%E4%B8%8E%E9%80%BB%E8%BE%91%E6%A0%B8/</link>
      <pubDate>Fri, 04 Nov 2016 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/cpu%E7%89%A9%E7%90%86%E6%A0%B8%E4%B8%8E%E9%80%BB%E8%BE%91%E6%A0%B8/</guid>
      <description>一、物理CPU  物理CPU数是指实际Server中插槽上的CPU个数 物理核数是指一个CPU上的物理核心数。 每个CPU上有一到多个物理核 物理总核数=物理CPU个数 X 每个物理CPU的核数  二、逻辑CPU  逻辑CPU是指处理器单元，它可以在与其它逻辑CPU并行执行。 一般所说的CPU核数是指逻辑CPU数。 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 如果采用了Intel的超线程技术（HT)，则上面公式的超线程数=2。即总逻辑CPU数为物理总核数的两倍  三、如何查看CPU信息 #Linux #查看CPU信息 cat /proc/cpuinfo #OUTPUT: #processor : 0 逻辑核ID #vendor_id : GenuineIntel #cpu family : 6 #model : 45 #model name : Intel(R) Xeon(R) CPU E5-2660 0 @ 2.20GHz #stepping : #cpu MHz : 2200.000 #cache size : 20480 KB #physical id : 0 物理CPU的编号 #siblings : 2 所在物理CPU有几个逻辑核 #core id : 0 物理核编号 #cpu cores : 2 所在物理CPU有几个物理核 #apicid : 0 #initial apicid : 0 #fpu : yes #fpu_exception : yes #cpuid level : 13 #wp : yes #flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts xtopology tsc_reliable nonstop_tsc aperfmperf unfair_spinlock pni pclmulqdq ssse3 cx16 sse4_1 sse4_2 popcnt aes xsave avx hypervisor lahf_lm ida arat xsaveopt pln pts dts #bogomips : 4400.</description>
    </item>
    
    <item>
      <title>监控系统状态的指令</title>
      <link>https://yesphet.github.io/posts/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E7%9A%84%E6%8C%87%E4%BB%A4/</link>
      <pubDate>Fri, 04 Nov 2016 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E7%9A%84%E6%8C%87%E4%BB%A4/</guid>
      <description>有标系统名称的为该系统特有
#查看系统运行时间、用户数、负载 $ uptime 16:20:43 up 50 days, 1:50, 1 user, load average: 0.00, 0.00, 0.00 #监控当前进程及简单系统状态,包括cpu占用，内存占用，load, $ top #查看load及活动用户 $ w #查看硬盘使用情况 $ df -h #查看所有监听端口 $ netstat -lntp #查看IO负载 $ iostat ######Linux##### #查看内存状态，-m，-k, -b可以指定单位 $ free #查看网卡信息，需要root权限 $ ethtool DEVNAME ######OS X###### #其实OS X直接打开自带的活动监视器，一目了然。。。 </description>
    </item>
    
    <item>
      <title>Unix目录结构</title>
      <link>https://yesphet.github.io/posts/unix%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/</link>
      <pubDate>Sun, 25 Sep 2016 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/unix%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/</guid>
      <description>参考：linux目录结构详解
 在大多数linux系统中使用命令 man hier就可以查看系统自带的目录结构介绍。
 / :根目录   /boot ：引导程序，内核等存放的目录。
 这个目录，包括了在引导过程中所必需的文件，引导程序的相关文件（例如grub，lilo以及相应的配置文件）以及Linux操作系统内核相关文件（例如vmlinuz）等一般都存放在这里。在最开始的启动阶段，通过引导程序将内核加载到内存，完成内核的启动，这个时候，虚拟文件系统还不存在，加载的内核虽然是从硬盘读取的，但是没经过Linux的虚拟文件系统，这是比较底层的东西来实现的。然后内核自己创建好虚拟文件系统，并且从虚拟文件系统的其他子目录中（例如/sbin 和 /etc）加载需要在开机启动的其他程序或者服务或者特定的动作。如果我们的机器中包含多个操作系统，那么可以通过修改这个目录中的某个配置文件（例如grub.conf）来调整启动的默认操作系统，系统启动的选择菜单，以及启动延迟等参数。
   /bin ：普通用户可以使用的命令的存放目录
 系统所需要的那些命令位于此目录，比如ls、cp、mkdir等命令；类似的目录还/usr/bin，/usr/local/bin等等。这个目录中的文件都是可执行的、普通用户都可以使用的命令。作为基础系统所需要的最基础的命令就是放在这里。
   /sbin ：超级用户可以使用的命令的存放目录
 存放大多涉及系统管理的命令（例如引导系统的init程序），是超级权限用户root的可执行命令存放地，普通用户无权限执行这个目录下的命令（但是时普通用户也可能会用到）。这个目录和/usr/sbin; /usr/X11R6/sbin或/usr/local/sbin等目录是相似的，我们要记住，凡是目录sbin中包含的都是root权限才能执行的，这样就行了。
   /lib ：/bin/和/sbin/中二进制文件必要的库文件。
 此目录下包含系统引导和在根用户执行命令时候所必需用到的共享库。类似的目录还有/usr/lib，/usr/local/lib等等。
   /dev ：设备文件目录。
 在Linux中设备都是以文件形式出现，这里的设备可以是硬盘，键盘，鼠标，网卡，终端，等设备，通过访问这些文件可以访问到相应的设备。设备文件可以使用mknod命令来创建，具体参见相应的命令；而为了将对这些设备文件的访问转化为对设备的访问，需要向相应的设备提供设备驱动模块（一般将设备驱动编译之后，生成的结果是一个*.ko类型的二进制文件，在内核启动之后，再通过insmod等命令加载相应的设备驱动之后，我们就可以通过设备文件来访问设备了）。一般来说，想要Linux系统支持某个设备，只要个东西：相应的硬件设备，支持硬件的驱动模块，以及相应的设备文件。
   /etc ：全局的配置文件存放目录。
 系统和程序一般都可以通过修改相应的配置文件，来进行配置。例如，要配置系统开机的时候启动那些程序，配置某个程序启动的时候显示什么样的风格等等。通常这些配置文件都集中存放在/etc目录中，所以想要配置什么东西的话，可以在/etc下面寻找我们可能需要修改的文件。一些大型套件，如X11，在 /etc 下它们自己的子目录。系统配置文件可以放在这里或在 /usr/etc。 不过所有程序总是在 /etc 目录下查找所需的配置文件，你也可以将这些文件链接到目录 /usr/etc。另外，还有一个需要注意的常见现象就是，当某个程序在某个用户下运行的时候，可能会在该用户的家目录中生成一个配置文件（一般这个文件最开始就是/etc下相应配置文件的拷贝，存放相应于“当前用户”的配置，这样当前用户可以通过配置这个家目录的配置文件，来改变程序的行为，并且这个行为只是该用户特有的。原因就是：一般来说一个程序启动，如果需要读取一些配置文件的话，它会首先读取当前用户家目录的配置文件，如果存在就使用；如果不存在它就到/etc下读取全局的配置文件进而启动程序。就是这个配置文件不自动生成，我们手动在自己的家目录中创建一个文件的话，也有许多程序会首先读取到这个家目录的文件并且以它的配置作为启动的选项（例如我们可以在家目录中创建vim程序的配置文件.vimrc，来配置自己的vim程序）。
   /home ：普通用户的家目录
 在Linux机器上，用户主目录通常直接或间接地置在此目录下。其结构通常由本地机的管理员来决定。
   /root ：用户root的$HOME目录</description>
    </item>
    
    <item>
      <title>单元测试测什么</title>
      <link>https://yesphet.github.io/posts/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E6%B5%8B%E4%BB%80%E4%B9%88/</link>
      <pubDate>Thu, 22 Sep 2016 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E6%B5%8B%E4%BB%80%E4%B9%88/</guid>
      <description>I get paid for code that works, not for tests, so my philosophy is to test as little as possible to reach a given level of confidence (I suspect this level of confidence is high compared to industry standards, but that could just be hubris). If I don’t typically make a kind of mistake (like setting the wrong variables in a constructor), I don’t test for it. I do tend to make sense of test errors, so I’m extra careful when I have logic with complicated conditionals.</description>
    </item>
    
    <item>
      <title>Shell下批量导入导出数据库</title>
      <link>https://yesphet.github.io/posts/shell%E4%B8%8B%E6%89%B9%E9%87%8F%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <pubDate>Wed, 24 Aug 2016 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/shell%E4%B8%8B%E6%89%B9%E9%87%8F%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <description>带mysql&amp;gt;前缀的命令为mysql命令
   导出所有库
mysqldump -uusername -ppassword --all-databases &amp;gt; all.sql
  导入所有库
mysql&amp;gt;source all.sql;
  导出某些库
mysqldump -uusername -ppassword --databases db1 db2 &amp;gt; db1db2.sql
  导入某些库
mysql&amp;gt;source db1db2.sql;
  导入某个库
mysql -uusername -ppassword db1 &amp;lt; db1.sql; 或
mysql&amp;gt;source db1.sql;   导出某些数据表
mysqldump -uusername -ppassword db1 table1 table2 &amp;gt; tb1tb2.sql   导入某些数据表
mysql -uusername -ppassword db1 &amp;lt; tb1tb2.sql 或
mysql&amp;gt; use db1; source tb1tb2.</description>
    </item>
    
    <item>
      <title>Windows下的shell脚本传到Linux下无法执行</title>
      <link>https://yesphet.github.io/posts/windows%E4%B8%8B%E7%9A%84shell%E8%84%9A%E6%9C%AC%E4%BC%A0%E5%88%B0linux%E4%B8%8B%E6%97%A0%E6%B3%95%E6%89%A7%E8%A1%8C/</link>
      <pubDate>Wed, 24 Aug 2016 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/windows%E4%B8%8B%E7%9A%84shell%E8%84%9A%E6%9C%AC%E4%BC%A0%E5%88%B0linux%E4%B8%8B%E6%97%A0%E6%B3%95%E6%89%A7%E8%A1%8C/</guid>
      <description>原因：windos下的.sh文件格式为dos格式。而linux只能执行格式为unix格式的脚本 解决办法：
 用vi或vim打开文件 执行set ff指令查看文件的格式，应该为fileformat=dos 修改format为unix。执行set ff=unix或 set fileformat=unix wq保存退出  </description>
    </item>
    
    <item>
      <title>Cookie和Session的区别</title>
      <link>https://yesphet.github.io/posts/cookie%E5%92%8Csession%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Mon, 18 Jul 2016 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/cookie%E5%92%8Csession%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
      <description>cookie保存在客户端本地，session保存在服务器 cookie的不安全性，可以通过修改本地的cookie进行cookie欺骗 当服务器的访问量很大的时候，session会占用较多的服务器性能 单个cookie保存的数据大小上限是4K  SessionID，用于服务器标识Session，服务器通过客户端发来的SessionID检索客户端对应的Session。SessionID一般放在Cookie中进行传递和保存。当Cookie被禁止时，还可以通过URL重写（将SessionID直接附加在URL地址后面），或者表单隐藏字段（服务器自动修改表单，添加一个隐藏字段，在表单提交时就能够把SessionID传递回服务器）来传递SessionID。</description>
    </item>
    
    <item>
      <title>Put和Post的区别</title>
      <link>https://yesphet.github.io/posts/put%E5%92%8Cpost%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Fri, 15 Jul 2016 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/put%E5%92%8Cpost%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
      <description>  首先，两者都能实现更新资源的功能。
  建议使用PUT执行更新操作，使用POST执行创建操作。
  区别：
  Post不是幂等（idempotent）的
对于一个接口，每次提交相同的动作，其产生的结果是不一致的，则使用post。比如一个减少100余额的接口，调用一次减少100，调用两次减少200，则使用Post。
  Put是幂等的
对于一个接口，每次提交相同的动作，其产生的结果一致，则使用put。比如一个修改文件名的接口，只要提交的文件名相同，调用多少次都产生相同的结果，则使用put。 Html4.0只支持post和get，所以使用post去完成put和delete的操作。因此针对PC端一般考虑post和get请求。 但在支持html5的客户端则需要考虑post,get,put和delete
    </description>
    </item>
    
    <item>
      <title>RESTful 设计风格</title>
      <link>https://yesphet.github.io/posts/restful-%E8%AE%BE%E8%AE%A1%E9%A3%8E%E6%A0%BC/</link>
      <pubDate>Tue, 12 Jul 2016 00:00:00 +0800</pubDate>
      
      <guid>https://yesphet.github.io/posts/restful-%E8%AE%BE%E8%AE%A1%E9%A3%8E%E6%A0%BC/</guid>
      <description>  REST(Representational State Transfer) REST 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是 RESTful。
  网络上的实体，都可以称为“资源”，比如网上的一张图片，一段视频。而每个“资源”，都应该有一个URI（统一资源定位符）与其对应，这个URI即该资源在网络上的唯一标识符。
  “资源”是实体，可以有多种表现形式，就像一段文本可以是txt、html、json等形式表现出来，这些形式称之为表现层。
  客户端如果想要操作服务器，即通过某种手段让服务器上的“资源”发生“状态转换（State Transfer）”，而这种转化是建立在“资源”的表现层上的，因此称之为 REST(Representational State Transfer)。
  客户端的手段就是HTTP协议。通过HTTP的四个动词：get,post,put,delete让服务器上的资源发生状态转化。
  综合上面的解释，我们总结一下什么是RESTful架构
 每一个URI代表一种资源; 客户端和服务器之间，传递这种资源的某种表现层; 客户端通过四个HTTP动词，对服务器端资源进行操作，实现&amp;quot;表现层状态转化&amp;rdquo;。    </description>
    </item>
    
  </channel>
</rss>